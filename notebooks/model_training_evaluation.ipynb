{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ba99d1-473c-464e-918a-3c7b4275e68f",
   "metadata": {},
   "source": [
    "# Spam Email Detection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project focuses on detecting spam emails using a dataset containing information from 5,172 randomly selected email files. The goal is to build a classification model that can accurately distinguish between spam and not-spam emails based on the content of the emails.\n",
    "\n",
    "## Source\n",
    "\n",
    "This dataset is available on Kaggele in the following link:\n",
    "\n",
    "> https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv\n",
    "\n",
    "## About the Dataset\n",
    "\n",
    "The dataset is provided in a CSV file with the following characteristics:\n",
    "\n",
    "- **Rows**: 5,172 rows, each representing an individual email.\n",
    "- **Columns**: 3,002 columns in total.\n",
    "  - **First Column**: Indicates the email name. The names have been anonymized with numbers to protect privacy.\n",
    "  - **Last Column**: Contains the labels for classification:\n",
    "    - `1` for spam emails.\n",
    "    - `0` for not-spam emails.\n",
    "  - **Remaining 3,000 Columns**: These columns represent the 3,000 most common words across all emails, excluding non-alphabetical characters. Each cell in these columns contains the count of the respective word in the corresponding email.\n",
    "\n",
    "This compact representation allows for efficient processing and analysis of email data without needing to work with separate text files.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "1. **Model Training**: Train the model with training dataset so that it can identify whether an email is spam or not.\n",
    "2. **Model Evaluation**: Evaluate the performance of the trained model using the evaluation metrics such as accuracy, precision, recall and F1 score.\n",
    "3. **Model Optimization**: Optimeze the performance of the model with cross validation and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613253de-a478-4207-8b7a-0b0f6a29392f",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8c13ed2-1d4f-4eed-beb8-d7c6ef1c599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model and evaluation metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d63585-3290-4f54-9de8-3904353c581e",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "74dc8e77-505e-4ac1-81a6-b05df85767bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Path\n",
    "data_path = \"../data\"\n",
    "model_path = \"../models\"\n",
    "# csv_path = os.path.join(data_path, \"emails_fr.csv\")\n",
    "csv_path = os.path.join(data_path, \"emails_or.csv\")\n",
    "# csv_path = os.path.join(data_path, \"emails_pca.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca0199e-0231-465b-b893-5daa27c41681",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60f66408-423e-449d-aea8-74fc7c8f5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "380df897-bfba-4570-944e-f060d840588c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  valued  \\\n",
       "0    0   0    1    0    0   0    2    0    0   0  ...         0    0       0   \n",
       "1    8  13   24    6    6   2  102    1   27  18  ...         0    0       0   \n",
       "2    0   0    1    0    0   0    8    0    0   4  ...         0    0       0   \n",
       "3    0   5   22    0    5   1   51    2   10   1  ...         0    0       0   \n",
       "4    7   6   17    1    5   2   57    0    9   3  ...         0    0       0   \n",
       "\n",
       "   lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0    0               0         0         0   0    0           0  \n",
       "1    0               0         0         0   1    0           0  \n",
       "2    0               0         0         0   0    0           0  \n",
       "3    0               0         0         0   0    0           0  \n",
       "4    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d8727f-c799-4ec4-9680-ffd341d932e3",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec6f93e3-b194-4c04-8ec1-a58ab67f6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input and output features\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09e2a98a-317f-45d6-abb3-65580f7ee3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd671a02-3725-40e6-b7cb-1b3aedcd37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the the data\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4cc9b-ef3b-4e51-8750-647752f3a5a8",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "21f41630-a471-4008-99d1-0758a6557fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a model\n",
    "def train_evaluate(model):\n",
    "    # Train the model with training set\n",
    "    model.fit(X_train_s, y_train)\n",
    "\n",
    "    # Predict on training and testing data\n",
    "    y_train_pred = model.predict(X_train_s)\n",
    "    y_test_pred = model.predict(X_test_s)\n",
    "\n",
    "    # print evaluation metrics for taring and testing\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EVALUATION METRICS FOR TRAINING\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, y_train_pred):.2f}\")\n",
    "    print(f\"Precision: {precision_score(y_train, y_train_pred):.2f}\")\n",
    "    print(f\"Recall: {recall_score(y_train, y_train_pred):.2f}\")\n",
    "    print(f\"F1: {f1_score(y_train, y_train_pred):.2f}\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EVALUATION METRICS FOR TESTING\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.2f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_test_pred):.2f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_test_pred):.2f}\")\n",
    "    print(f\"F1: {f1_score(y_test, y_test_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54d90dda-010d-41ed-babe-15e24e3bdb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION METRICS FOR TRAINING\n",
      "============================================================\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1: 1.00\n",
      "\n",
      "============================================================\n",
      "EVALUATION METRICS FOR TESTING\n",
      "============================================================\n",
      "Accuracy: 0.94\n",
      "Precision: 0.88\n",
      "Recall: 0.89\n",
      "F1: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Train the Decision Tree Classifier with training data and evaluate performance with 4 metrics\n",
    "dtc = DecisionTreeClassifier()\n",
    "train_evaluate(dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256098b8-d5bb-4fbc-9f9f-53b762644315",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "- Training with defalut hyperparameter gives **accuracy** of **94%**.\n",
    "- Precision is critical when false positives are costly or harmful. For example, in spam detection, if an email is incorrectly marked as spam (a false positive), the user might miss important messages. We found **precision** of **88%**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba276824-63c2-4995-84b6-f4c4e12350eb",
   "metadata": {},
   "source": [
    "### Model Optimization\n",
    "\n",
    "- Try to find the optimal model using hyperparameter tuning and corss validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "befbec9f-d9dc-41a5-b715-566274d3f065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9149061594077359\n"
     ]
    }
   ],
   "source": [
    "# KFold Cross validation\n",
    "kf = KFold(n_splits= 5)\n",
    "\n",
    "dtc_cv = DecisionTreeClassifier()\n",
    "\n",
    "# Cross validation\n",
    "cvs = cross_val_score(dtc_cv, X, y, cv= kf)\n",
    "print(cvs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a4dbc824-ce38-43e7-8ee9-c13181d5634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyperparameter\n",
    "param_dict = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "    \"max_depth\": [None, 2, 3, 4, 5],\n",
    "    \"min_samples_split\": [2, 3, 4, 5],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "54e542f2-7683-4ad9-989e-546a23f8fd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "Best Parameter set: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "Best Score: 0.9247917027592022\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "cv_model = DecisionTreeClassifier()\n",
    "\n",
    "gvcv = GridSearchCV(estimator= cv_model,\n",
    "                   param_grid= param_dict,\n",
    "                   cv= 5,\n",
    "                   verbose= 1)\n",
    "gvcv.fit(X, y)\n",
    "best_params = gvcv.best_params_\n",
    "print(f\"Best Parameter set: {best_params}\")\n",
    "print(f\"Best Score: {gvcv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a63114e-82b4-408e-be7a-78d65bd846ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION METRICS FOR TRAINING\n",
      "============================================================\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1: 1.00\n",
      "\n",
      "============================================================\n",
      "EVALUATION METRICS FOR TESTING\n",
      "============================================================\n",
      "Accuracy: 0.95\n",
      "Precision: 0.90\n",
      "Recall: 0.92\n",
      "F1: 0.91\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate with best parameters\n",
    "model = DecisionTreeClassifier(**best_params)\n",
    "train_evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5613ccd9-53f1-44fa-a5c5-1b7be581ed77",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- We found the optimal model after hyperparameter tuning which increases the accuracy to **95%** and also increases the precision also. It has the **precision** of **90%**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b1263f-f6e0-427a-8d3b-53dfbd2fd5a6",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a08fd556-df2c-4db3-8223-27d9de6035fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimal model for future use to identify spam email.\n",
    "dt_model_path = os.path.join(model_path, \"spam_detector_dt.pkl\")\n",
    "with open(dt_model_path, \"wb\") as dt_model:\n",
    "    pickle.dump(model, dt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a28719-4122-457f-a829-c60ca37fec60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
